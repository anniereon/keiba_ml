{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4921794-0865-4b8f-b7dc-e8da59a58380",
   "metadata": {},
   "outputs": [],
   "source": [
    "### インポート ###\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from datetime import datetime\n",
    "import time\n",
    "import re\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, TypeVar, Generic\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ed341ce-96e9-4538-8c2c-c194ca6c9426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "脚質: {1: '逃げ', 2: '先行', 3: '差し', 4: '追込'}\n",
      "最小許容有効レコード数: {8: 8, 9: 9}\n",
      "最小騎手出走数: 100\n",
      "対象コース: {('園田', 'ダ', 1400, '右'), ('名古屋', 'ダ', 1500, '右'), ('高知', 'ダ', 1300, '右'), ('笠松', 'ダ', 1400, '右'), ('浦和', 'ダ', 1500, '左'), ('園田', 'ダ', 1230, '右'), ('船橋', 'ダ', 1500, '左'), ('笠松', 'ダ', 1600, '右'), ('川崎', 'ダ', 1400, '左'), ('船橋', 'ダ', 1200, '左'), ('水沢', 'ダ', 850, '右'), ('姫路', 'ダ', 1400, '右'), ('門別', 'ダ', 1000, '右'), ('佐賀', 'ダ', 1400, '右'), ('浦和', 'ダ', 1400, '左'), ('金沢', 'ダ', 1500, '右'), ('門別', 'ダ', 1200, '右'), ('川崎', 'ダ', 900, '左'), ('高知', 'ダ', 1400, '右'), ('水沢', 'ダ', 1400, '右'), ('佐賀', 'ダ', 1300, '右'), ('盛岡', 'ダ', 1200, '左')}\n",
      "シミュレーション回数: 10000\n"
     ]
    }
   ],
   "source": [
    "# =====\n",
    "# 設定\n",
    "# =====\n",
    "\n",
    "### 設定ファイル ###\n",
    "df_config_style = pd.read_excel(\"C:\\\\keiba\\\\tool\\\\config.xlsx\", sheet_name=\"style\", header=0)\n",
    "df_config_min_records = pd.read_excel(\"C:\\\\keiba\\\\tool\\\\config.xlsx\", sheet_name=\"min_records\", header=0)\n",
    "df_config_features = pd.read_excel(\"C:\\\\keiba\\\\tool\\\\config.xlsx\", sheet_name=\"features\", header=0)\n",
    "df_config_target_courses = pd.read_excel(\"C:\\\\keiba\\\\tool\\\\config.xlsx\", sheet_name=\"target_courses\", header=0)\n",
    "df_config_num_sumulation = pd.read_excel(\"C:\\\\keiba\\\\tool\\\\config.xlsx\", sheet_name=\"num_sumulation\", header=0)\n",
    "# 脚質\n",
    "STYLE_MAP = df_config_style.set_index('key')['value'].to_dict()\n",
    "print(f'脚質: {STYLE_MAP}')\n",
    "REVERSE_STYLE_MAP = {v: k for k, v in STYLE_MAP.items()}\n",
    "# 最小許容有効レコード数\n",
    "MIN_RECORDS_MAP = df_config_min_records.set_index('num_horses')['min_records'].to_dict()\n",
    "print(f'最小許容有効レコード数: {MIN_RECORDS_MAP}')\n",
    "# 最小騎手出走数\n",
    "FEATURES_MAP = df_config_features.set_index('key')['value'].to_dict()\n",
    "MIN_JOCKEY_RECORDS = FEATURES_MAP.get('min_jockey_records')\n",
    "print(f'最小騎手出走数: {MIN_JOCKEY_RECORDS}')\n",
    "# 対象コース\n",
    "# 前準備：Excelのコース設定を、高速に検索できる「集合(set)」形式に変換\n",
    "target_courses_set = set(\n",
    "    df_config_target_courses[['racecourse', 'ground', 'distance', 'direction']]\n",
    "    .itertuples(index=False, name=None)\n",
    ")\n",
    "print(f'対象コース: {target_courses_set}')\n",
    "# シミュレーション回数\n",
    "NUM_SIMULATIONS = df_config_num_sumulation.iloc[0, 0]\n",
    "print(f'シミュレーション回数: {NUM_SIMULATIONS}')\n",
    "### 共通オブジェクト ###\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdbaee24-ddd0-4fde-97c4-94ae20704708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========\n",
    "# メソッド\n",
    "# ========\n",
    "\n",
    "def calculate_recent_time_index_avg(row, df):\n",
    "    \"\"\"\n",
    "    特定の馬(horse_id)の直近2走の平均time_indexを計算する\n",
    "    \"\"\"\n",
    "    target_id = row['horse_id']\n",
    "    target_date = row['race_date']\n",
    "    \n",
    "    # 1. dfから同じhorse_id、かつ今回のrace_dateより前のデータを抽出\n",
    "    # ※昇順にソート（直近が下に来るようにする）\n",
    "    df_filtered = df[\n",
    "        (df['horse_id'] == target_id) & \n",
    "        (df['race_date'] < target_date)\n",
    "    ].sort_values('race_date')\n",
    "    \n",
    "    # 2. time_indexがNaNでないものを抽出\n",
    "    df_valid = df_filtered.dropna(subset=['time_index'])\n",
    "    \n",
    "    # 3. 有効なデータが2つ以上あるか判定\n",
    "    if len(df_valid) >= 2:\n",
    "        # 下から2つ（直近2走）を選択して平均を出す\n",
    "        avg_index = df_valid.tail(2)['time_index'].mean()\n",
    "        return avg_index\n",
    "    else:\n",
    "        # 2回未満ならNaN\n",
    "        return np.nan\n",
    "\n",
    "def calculate_jockey_win_rate(row, df):\n",
    "    \"\"\"\n",
    "    特定の騎手(jockey_id)の直近 MIN_JOCKEY_RECORDS 走（有効データ）の勝率を計算する\n",
    "    \"\"\"\n",
    "    target_id = row['jockey_id']\n",
    "    target_date = row['race_date']\n",
    "    \n",
    "    # 1. その騎手の、今回のレース日より前のデータを抽出\n",
    "    # 2. かつ finish_rank が NaN でないものに絞る\n",
    "    # 3. 日付順（昇順）にソート\n",
    "    df_jockey_past = df[\n",
    "        (df['jockey_id'].astype(str).str.zfill(5) == str(target_id).zfill(5)) & \n",
    "        (df['race_date'] < target_date) &\n",
    "        (df['finish_rank'].notna())\n",
    "    ].sort_values('race_date')\n",
    "    \n",
    "    # 4. 直近recent_num個のレコードを抽出（recent_num個なければ全件）\n",
    "    df_recent = df_jockey_past.tail(MIN_JOCKEY_RECORDS)\n",
    "    \n",
    "    # レコード数をカウント（分母）\n",
    "    total_count = len(df_recent)\n",
    "\n",
    "    if total_count == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    # 5. finish_rank が 3 以下であるレコード数をカウント（分子）\n",
    "    win_count = (df_recent['finish_rank'].astype(int) <= 3).sum()\n",
    "    \n",
    "    # 勝率を計算して返す\n",
    "    return win_count / total_count\n",
    "\n",
    "def predict_position_half_type(group):\n",
    "    '''\n",
    "    以下でソート\n",
    "    1. 脚質順\n",
    "    2. タイム指数順\n",
    "    '''\n",
    "    group = group.sort_values([\"style_id\", \"time_index_avg_recent_2\"], ascending=[True, False])\n",
    "    n = len(group)\n",
    "    mid = n // 2\n",
    "    res = pd.Series(index=group.index, dtype=str)\n",
    "    res.iloc[:mid] = \"front\"\n",
    "    res.iloc[mid:] = \"back\"\n",
    "    return res\n",
    "\n",
    "def check_race_validity(group, target_courses):\n",
    "    # --- 1. コース条件のチェック ---\n",
    "    course_info = (\n",
    "        group['racecourse'].iloc[0], \n",
    "        group['ground'].iloc[0], \n",
    "        group['distance'].iloc[0], \n",
    "        group['direction'].iloc[0]\n",
    "    )\n",
    "    if course_info not in target_courses:\n",
    "        return False\n",
    "    # --- 2. 頭数のチェック ---\n",
    "    num_horses = group['num_horses'].iloc[0]\n",
    "    if num_horses not in MIN_RECORDS_MAP:\n",
    "        return False  \n",
    "    # --- 3. 【今回の本題】特定の2つの変数による「レース丸ごと除外」チェック ---\n",
    "    # 判定対象の列を絞り込む\n",
    "    core_features = ['time_index_pred_from_race_avg', f'jockey_top3_rate_recent_{MIN_JOCKEY_RECORDS}']\n",
    "    # 1つでも欠損（NaN）がある行が、そのグループ（レース）内に「存在する」か判定\n",
    "    # any(axis=1)で「行に欠損があるか」、さらにany()で「グループ全体で1行でもあるか」を確認\n",
    "    if group[core_features].isna().any(axis=1).any():\n",
    "        return False\n",
    "    # ここまで来れば、全頭の「タイム指数」と「騎手データ」が揃っていることが確定\n",
    "    return True\n",
    "\n",
    "def filter_valid_data(df, target_courses):\n",
    "    \"\"\"\n",
    "    メインのフィルタリング実行関数\n",
    "    \"\"\"\n",
    "    # 統合したチェック関数を適用\n",
    "    # 引数を渡すために lambda を使用\n",
    "    valid_mask = df.groupby('race_id').apply(\n",
    "        lambda x: check_race_validity(x, target_courses)\n",
    "    )\n",
    "    # 有効なrace_idだけを抽出\n",
    "    valid_race_ids = valid_mask[valid_mask].index\n",
    "    df_filtered = df[df['race_id'].isin(valid_race_ids)].copy()\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "def create_dl_model(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(input_dim,)),\n",
    "        Dropout(0.5),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid') \n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05d42a8b-8ca7-4abd-97e3-cf6b21ecf10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainデータ読み込み：開始\n",
      "trainデータ読み込み：終了\n",
      "shutubaデータ読み込み：開始\n",
      "shutubaデータ読み込み：終了\n"
     ]
    }
   ],
   "source": [
    "# =================\n",
    "# 学習データ読み込み\n",
    "# =================\n",
    "print(\"trainデータ読み込み：開始\")\n",
    "df_train = pd.read_csv(\"C:\\\\keiba\\\\tool\\\\train\\\\train.csv\", header=0, encoding='cp932')\n",
    "print(\"trainデータ読み込み：終了\")\n",
    "### shutubaデータ読み込み ###\n",
    "print(\"shutubaデータ読み込み：開始\")\n",
    "list_shutuba_files = glob.glob(\"C:\\\\keiba\\\\tool\\\\shutuba\\\\shutuba*.csv\")\n",
    "if list_shutuba_files:\n",
    "    df_shutuba_raw = pd.read_csv(list_shutuba_files[0], header=0)\n",
    "else:\n",
    "    print(\"該当するファイルが見つかりませんでした。\")\n",
    "print(\"shutubaデータ読み込み：終了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9acef519-d3df-4764-b440-430e222aa683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "説明変数作成：開始\n",
      "    予想タイム指数計算：開始\n",
      "    予想タイム指数計算：終了\n",
      "    騎手複勝率計算：開始\n",
      "    騎手複勝率計算：終了\n",
      "    対象レース絞り込み：開始\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryo\\AppData\\Local\\Temp\\ipykernel_13400\\3093023001.py:106: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  valid_mask = df.groupby('race_id').apply(\n",
      "C:\\Users\\ryo\\AppData\\Local\\Temp\\ipykernel_13400\\3093023001.py:106: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  valid_mask = df.groupby('race_id').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    対象レース絞り込み：終了\n",
      "    コース×頭数×馬番別勝率計算：開始\n",
      "    コース×頭数×馬番別勝率計算：終了\n",
      "    ポジション（front / back）予想作成：開始\n",
      "    ポジション（front / back）予想作成：終了\n",
      "    予想ポジション別勝率計算：開始\n",
      "    予想ポジション別勝率計算：終了\n",
      "    予想ポジション比率別勝率計算：開始\n",
      "    予想ポジション比率別勝率計算：終了\n",
      "説明変数作成：終了\n"
     ]
    }
   ],
   "source": [
    "# =============\n",
    "# 説明変数作成\n",
    "# =============\n",
    "print(\"説明変数作成：開始\")\n",
    "df_pred = df_shutuba_raw.copy()\n",
    "\n",
    "### 予想タイム指数 ###\n",
    "print(\"    予想タイム指数計算：開始\")\n",
    "# 直近過去2レースのタイム指数の平均値\n",
    "df_pred['time_index_avg_recent_2'] = df_pred.apply(calculate_recent_time_index_avg, axis=1, args=(df_train,))\n",
    "df_pred['time_index_avg_recent_2_race_avg'] = df_pred.groupby('race_id')['time_index_avg_recent_2'].transform('mean')\n",
    "df_pred['time_index_pred_from_race_avg'] = df_pred['time_index_avg_recent_2'] - df_pred['time_index_avg_recent_2_race_avg']\n",
    "# メモ：NaNをどう埋めるかは後で考える。front/back判定でも使う\n",
    "print(\"    予想タイム指数計算：終了\")\n",
    "\n",
    "### 騎手複勝率 ###\n",
    "print(\"    騎手複勝率計算：開始\")\n",
    "df_pred[f'jockey_top3_rate_recent_{MIN_JOCKEY_RECORDS}'] = df_pred.apply(calculate_jockey_win_rate, axis=1, args=(df_train,))\n",
    "print(\"    騎手複勝率計算：終了\")\n",
    "\n",
    "### 対象レースに絞る\n",
    "print(\"    対象レース絞り込み：開始\")\n",
    "df_train = filter_valid_data(df_train, target_courses_set)\n",
    "df_train = df_train.dropna(subset=['finish_rank'])\n",
    "df_pred = filter_valid_data(df_pred, target_courses_set)\n",
    "print(\"    対象レース絞り込み：終了\")\n",
    "\n",
    "### コース×頭数×馬番別勝率\n",
    "print(\"    コース×頭数×馬番別勝率計算：開始\")\n",
    "keys = ['racecourse', 'ground', 'distance', 'direction', 'num_horses', 'horse_number']\n",
    "stats_df = df_train.groupby(keys)['finish_rank'].agg([\n",
    "    ('win_count', lambda x: (pd.to_numeric(x, errors='coerce') == 1).sum()),\n",
    "    ('total_count', 'count')\n",
    "]).reset_index()\n",
    "stats_df['condition_win_rate'] = stats_df['win_count'] / stats_df['total_count']\n",
    "df_pred = pd.merge(df_pred, stats_df[keys + ['condition_win_rate']], on=keys, how='left')\n",
    "print(\"    コース×頭数×馬番別勝率計算：終了\")\n",
    "\n",
    "### ポジションに紐づく勝率計算 ###\n",
    "print(\"    ポジション（front / back）予想作成：開始\")\n",
    "df_pred[\"style_id\"] = df_pred[\"style_pred\"].map(REVERSE_STYLE_MAP)\n",
    "\n",
    "df_pred = df_pred.sort_values([\"race_id\", \"style_id\", \"time_index_avg_recent_2\"], \n",
    "                             ascending=[True, True, False])\n",
    "df_pred['temp_rank'] = df_pred.groupby(\"race_id\").cumcount()\n",
    "df_pred[\"position_half_type_pred\"] = np.where(\n",
    "    df_pred['temp_rank'] < (df_pred['num_horses'] // 2), \n",
    "    \"front\", \n",
    "    \"back\"\n",
    ")\n",
    "df_pred = df_pred.drop(columns=['temp_rank'])\n",
    "\n",
    "print(\"    ポジション（front / back）予想作成：終了\")\n",
    "\n",
    "print(\"    予想ポジション別勝率計算：開始\")\n",
    "\n",
    "keys = ['racecourse', 'ground', 'distance', 'direction', 'num_horses', 'position_half_type_pred']\n",
    "stats = df_train.groupby(keys)['finish_rank'].agg([\n",
    "    ('win_count', lambda x: (pd.to_numeric(x, errors='coerce') == 1).sum()),\n",
    "    ('total_count', 'count')\n",
    "]).reset_index()\n",
    "stats['position_half_type_win_rate'] = stats['win_count'] / stats['total_count']\n",
    "# predデータのコース×頭数×(front/back)に紐づく勝率を割り当てる\n",
    "df_pred = pd.merge(\n",
    "    df_pred, \n",
    "    stats[keys + ['position_half_type_win_rate']], \n",
    "    on=keys, \n",
    "    how='left'\n",
    ")\n",
    "print(\"    予想ポジション別勝率計算：終了\")\n",
    "\n",
    "print(\"    予想ポジション比率別勝率計算：開始\")\n",
    "\n",
    "df_train['front_count'] = df_train.groupby('race_id')['position_half_type_pred'].transform(lambda x: (x == 'front').sum())\n",
    "df_train['back_count'] = df_train.groupby('race_id')['position_half_type_pred'].transform(lambda x: (x == 'back').sum())\n",
    "keys = ['num_horses', 'front_count', 'back_count', 'position_half_type_pred']\n",
    "stats = df_train.groupby(keys)['finish_rank'].agg(\n",
    "    composition_pos_win_rate = lambda x: (pd.to_numeric(x, errors='coerce') == 1).sum() / len(x)\n",
    ").reset_index()\n",
    "df_pred['front_count'] = df_pred.groupby('race_id')['position_half_type_pred'].transform(lambda x: (x == 'front').sum())\n",
    "df_pred['back_count'] = df_pred.groupby('race_id')['position_half_type_pred'].transform(lambda x: (x == 'back').sum())\n",
    "df_pred = pd.merge(df_pred, stats, on=keys, how='left')\n",
    "\n",
    "print(\"    予想ポジション比率別勝率計算：終了\")\n",
    "\n",
    "print(\"説明変数作成：終了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79d51861-5485-4505-b445-fdf0c238ee87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "モデル作成：開始\n",
      "モデル作成：終了\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryo\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# ==========\n",
    "# モデル作成\n",
    "# ==========\n",
    "\n",
    "print(\"モデル作成：開始\")\n",
    "\n",
    "### 説明変数 ###\n",
    "features = [\n",
    "    'time_index_pred_from_race_avg',\n",
    "    f'jockey_top3_rate_recent_{MIN_JOCKEY_RECORDS}',\n",
    "    'condition_win_rate',\n",
    "    'position_half_type_win_rate',\n",
    "    'composition_pos_win_rate'\n",
    "]\n",
    "\n",
    "### DeepLearningモデル作成 ###\n",
    "dl_model = create_dl_model(len(features))\n",
    "\n",
    "print(\"モデル作成：終了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a23aebcc-39bf-4de2-b814-dac78d67b946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習：開始\n",
      "学習：終了\n"
     ]
    }
   ],
   "source": [
    "# =====\n",
    "# 学習\n",
    "# =====\n",
    "\n",
    "print(\"学習：開始\")\n",
    "\n",
    "### 学習データ ###\n",
    "X_train = df_train[features]\n",
    "y_train = df_train['relative_rank_bin']\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "### 学習 ###\n",
    "dl_model.fit(X_train_scaled, y_train, epochs=20, batch_size=16, verbose=0)\n",
    "\n",
    "print(\"学習：終了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0834810e-bfff-4f04-a5c7-42c571c8a5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "予想：開始\n",
      "予想：終了\n"
     ]
    }
   ],
   "source": [
    "# =====\n",
    "# 予想\n",
    "# =====\n",
    "\n",
    "print(\"予想：開始\")\n",
    "\n",
    "### 予想データ ###\n",
    "X_pred = df_pred[features]\n",
    "X_pred_scaled = scaler.transform(X_pred)\n",
    "\n",
    "### 予想（上位半分に入る確率） ###\n",
    "df_pred[\"pred_prob\"] = dl_model.predict(X_pred_scaled, verbose=0).flatten()\n",
    "\n",
    "print(\"予想：終了\")\n",
    "\n",
    "df_pred.to_csv(\"C:\\\\keiba\\\\tool\\\\pred\\\\pred.csv\", index=False, encoding=\"cp932\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a88f5e64-1a06-4122-93ad-5384d6e23bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============\n",
    "# シミュレーション\n",
    "# ===============\n",
    "\n",
    "# 予想データのレースIDのリストを作成\n",
    "list_race_id = df_pred['race_id'].unique().tolist()\n",
    "# レースごとにループ処理\n",
    "all_processed_races = []\n",
    "for race_id in list_race_id:\n",
    "    # 1. 抽出\n",
    "    df_race = df_pred[df_pred['race_id'] == race_id].copy()\n",
    "    df_pred_prob = df_race[\"pred_prob\"].values\n",
    "    h_nums = df_race[\"horse_number\"].values\n",
    "    # 2. シミュレーション\n",
    "    dic_win_counts = {h: 0 for h in h_nums}\n",
    "    for _ in range(NUM_SIMULATIONS):\n",
    "        idx = np.argmax(df_pred_prob + np.random.normal(0, 0.09, len(df_pred_prob)))\n",
    "        dic_win_counts[h_nums[idx]] += 1\n",
    "    # 3. win_rateカラムを追加\n",
    "    df_race['win_rate'] = df_race['horse_number'].map(lambda x: dic_win_counts[x] / NUM_SIMULATIONS)\n",
    "    # 4. リストに追加\n",
    "    all_processed_races.append(df_race)\n",
    "# --- ループ終了後 ---\n",
    "# 5. 全てのレースを一つのデータフレームに結合（これがマージに相当します）\n",
    "df_pred = pd.concat(all_processed_races).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22ef7990-4869-4104-9d89-191b2a2ee9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============\n",
    "# 出力\n",
    "# ===============\n",
    "\n",
    "df_pred.to_csv(\"C:\\\\keiba\\\\tool\\\\pred\\\\pred.csv\", index=False, encoding=\"cp932\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
