{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4921794-0865-4b8f-b7dc-e8da59a58380",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ###\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from datetime import datetime\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, TypeVar, Generic\n",
    "import json\n",
    "import os\n",
    "import logging\n",
    "import functools\n",
    "from pathlib import Path\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6185ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_jupyter():\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal IPython\n",
    "        else:\n",
    "            return False  # Other shell type\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1ed833-847b-4abf-9fad-f560eb87036d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### å®šæ•° ###\n",
    "\n",
    "# ãƒ­ã‚°\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    filename=f\"C:\\\\keiba\\\\tool\\\\log\\\\{datetime.now().strftime('%Y%m%d_app.log')}\",\n",
    "    encoding='utf-8',\n",
    "    force=True\n",
    ")\n",
    "# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿\n",
    "df_config_racecourse = pd.read_excel(\"C:\\\\keiba\\\\tool\\\\config.xlsx\", sheet_name=\"racecourse\", header=0)\n",
    "df_config_style = pd.read_excel(\"C:\\\\keiba\\\\tool\\\\config.xlsx\", sheet_name=\"style\", header=0)\n",
    "df_config_scrape = pd.read_excel(\"C:\\\\keiba\\\\tool\\\\config.xlsx\", sheet_name=\"scrape\", header=None, index_col=0)\n",
    "df_config_netkeiba = pd.read_excel(\"C:\\\\keiba\\\\tool\\\\config.xlsx\", sheet_name=\"netkeiba\", header=None, index_col=0)\n",
    "# å¯¾è±¡ç«¶é¦¬å ´ã¨ãƒ¬ãƒ¼ã‚¹\n",
    "PLACE_MAP = df_config_racecourse.set_index('key')['value'].to_dict()\n",
    "print(f\"ç«¶é¦¬å ´: {PLACE_MAP}\")\n",
    "# è„šè³ª\n",
    "STYLE_MAP = df_config_style.set_index('key')['value'].to_dict()\n",
    "print(f\"è„šè³ª: {STYLE_MAP}\")\n",
    "# ãƒ¬ãƒ¼ã‚¹ç•ªå·\n",
    "RACE_NUMBERS = [f\"{i:02d}\" for i in range(1, 13)]\n",
    "# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°\n",
    "PATH_CHROME_DRIVER = df_config_scrape.loc[\"PATH_CHROME_DRIVER\"].iloc[0]\n",
    "# netkeiba\n",
    "LOGIN_URL = df_config_netkeiba.loc[\"LOGIN_URL\"].iloc[0]\n",
    "LOGIN_ID = df_config_netkeiba.loc[\"LOGIN_ID\"].iloc[0]\n",
    "LOGIN_PASSWORD = df_config_netkeiba.loc[\"LOGIN_PASSWORD\"].iloc[0]\n",
    "RACE_LIST_URL = df_config_netkeiba.loc[\"RACE_LIST_URL\"].iloc[0]\n",
    "if not is_jupyter() and len(sys.argv) > 1:\n",
    "    MODE = sys.argv[1]\n",
    "else:\n",
    "    MODE = df_config_netkeiba.loc[\"MODE\"].iloc[0]\n",
    "# ãƒ¬ãƒ¼ã‚¹å˜ä½\n",
    "print(f\"MODE: {MODE}\")\n",
    "if MODE == \"shutuba\":\n",
    "    SELECTOR_RACECOURSE = df_config_netkeiba.loc[\"SELECTOR_RACECOURSE_SHUTUBA\"].iloc[0]\n",
    "    SELECTOR_RACE_NUMBER = df_config_netkeiba.loc[\"SELECTOR_RACE_NUMBER_SHUTUBA\"].iloc[0]\n",
    "    SELECTOR_NUM_HORSES = df_config_netkeiba.loc[\"SELECTOR_NUM_HORSES_SHUTUBA\"].iloc[0]\n",
    "    XPATH_RACE_INFO = df_config_netkeiba.loc[\"XPATH_RACE_INFO_SHUTUBA\"].iloc[0]\n",
    "elif MODE == \"result\":\n",
    "    SELECTOR_RACECOURSE = df_config_netkeiba.loc[\"SELECTOR_RACECOURSE_RESULT\"].iloc[0]\n",
    "    SELECTOR_RACE_NUMBER = df_config_netkeiba.loc[\"SELECTOR_RACE_NUMBER_RESULT\"].iloc[0]\n",
    "    SELECTOR_NUM_HORSES = df_config_netkeiba.loc[\"SELECTOR_NUM_HORSES_RESULT\"].iloc[0]\n",
    "    XPATH_RACE_INFO = df_config_netkeiba.loc[\"XPATH_RACE_INFO_RESULT\"].iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ad7930-289b-47ac-8b94-3b7dea43aa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ã‚¯ãƒ©ã‚¹ ###\n",
    "\n",
    "# é¦¬ãƒ‡ãƒ¼ã‚¿ï¼ˆShutubaï¼‰\n",
    "@dataclass\n",
    "class Horse_Shutuba:\n",
    "    \"\"\"å‡ºèµ°é¦¬ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹\"\"\"\n",
    "    horse_id: str\n",
    "    horse_name: str\n",
    "    jockey_id: str\n",
    "    jockey_name: str\n",
    "    popularity: str\n",
    "    odds: str\n",
    "    sex_and_age: str\n",
    "    weight: str\n",
    "    horse_number: str\n",
    "    frame_number: str\n",
    "    position_1_top_pred: str\n",
    "    position_1_left_pred: str\n",
    "    position_2_top_pred: str\n",
    "    position_2_left_pred: str\n",
    "    position_3_top_pred: str\n",
    "    position_3_left_pred: str\n",
    "    position_4_top_pred: str\n",
    "    position_4_left_pred: str \n",
    "    position_1_top_pred_jockey_tendency: str\n",
    "    position_1_left_pred_jockey_tendency: str\n",
    "    position_2_top_pred_jockey_tendency: str\n",
    "    position_2_left_pred_jockey_tendency: str\n",
    "    position_3_top_pred_jockey_tendency: str\n",
    "    position_3_left_pred_jockey_tendency: str\n",
    "    position_4_top_pred_jockey_tendency: str\n",
    "    position_4_left_pred_jockey_tendency: str\n",
    "    style_pred: str\n",
    "    impost: str\n",
    "    last_3_furlongs_pred: str\n",
    "\n",
    "# é¦¬ãƒ‡ãƒ¼ã‚¿ï¼ˆResultï¼‰\n",
    "@dataclass\n",
    "class Horse_Result:\n",
    "    \"\"\"å‡ºèµ°é¦¬ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹\"\"\"\n",
    "    finish_rank: str\n",
    "    frame_number: str\n",
    "    horse_number: str\n",
    "    horse_id: str\n",
    "    horse_name: str\n",
    "    sex_and_age: str\n",
    "    impost: str    \n",
    "    jockey_id: str\n",
    "    jockey_name: str\n",
    "    time: str\n",
    "    diff: str    \n",
    "    popularity: str\n",
    "    odds: str\n",
    "    last_3_furlongs: str\n",
    "    weight: str\n",
    "\n",
    "# ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ï¼ˆShutubaï¼‰\n",
    "T = TypeVar('T')\n",
    "@dataclass\n",
    "class Race:\n",
    "    \"\"\"ãƒ¬ãƒ¼ã‚¹ã®åŸºæœ¬æƒ…å ±ã¨å‡ºèµ°é¦¬ãƒªã‚¹ãƒˆã‚’ä¿æŒã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹\"\"\"\n",
    "    race_id: str\n",
    "#    race_name: str\n",
    "    race_date: str\n",
    "    race_time: str\n",
    "    num_horses: str\n",
    "    race_number: int\n",
    "#    weather_name: str\n",
    "#    track_condition_name: str\n",
    "    racecourse: str\n",
    "    ground: str\n",
    "    distance: str\n",
    "    direction:  str\n",
    "    reliability: str\n",
    "    opinion: str\n",
    "    position_1: str\n",
    "    position_2: str\n",
    "    position_3: str\n",
    "    position_4: str    \n",
    "    horses: List[T] = field(default_factory=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f882b7-efbe-49bc-9bc0-ad8d3d33799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### é–¢æ•° ###\n",
    "def log_step(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        # ãƒ¡ã‚½ãƒƒãƒ‰é–‹å§‹ã®ãƒ­ã‚°\n",
    "        logging.info(f\"[é–‹å§‹] {func.__name__} ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚\")\n",
    "        \n",
    "        try:\n",
    "            # æœ¬æ¥ã®ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆé–¢æ•°ï¼‰ã‚’å®Ÿè¡Œ\n",
    "            result = func(*args, **kwargs)\n",
    "            \n",
    "            # ãƒ¡ã‚½ãƒƒãƒ‰çµ‚äº†ã®ãƒ­ã‚°\n",
    "            logging.info(f\"[å®Œäº†] {func.__name__} ãŒæ­£å¸¸ã«çµ‚äº†ã—ã¾ã—ãŸã€‚\")\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            # ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã®ãƒ­ã‚°\n",
    "            logging.error(f\"[å¤±æ•—] {func.__name__} ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")\n",
    "            raise  # ã‚¨ãƒ©ãƒ¼ã‚’ãã®ã¾ã¾ä¸Šã«æŠ•ã’ã‚‹\n",
    "            \n",
    "    return wrapper\n",
    "\n",
    "def is_xpath_present(driver, xpath):\n",
    "    return len(driver.find_elements(By.XPATH, xpath)) > 0\n",
    "\n",
    "def extract_style_values(style_str):\n",
    "    \"\"\"\n",
    "    styleæ–‡å­—åˆ—ã‹ã‚‰topã¨leftã®æ•°å€¤ã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°\n",
    "    \"\"\"\n",
    "    # æ­£è¦è¡¨ç¾ã®è§£èª¬:\n",
    "    # -?    : ãƒã‚¤ãƒŠã‚¹è¨˜å·ãŒã‚ã£ã¦ã‚‚ãªãã¦ã‚‚è‰¯ã„\n",
    "    # [\\d\\.]+ : æ•°å­—ã¾ãŸã¯ãƒ‰ãƒƒãƒˆãŒ1å›ä»¥ä¸Šç¶šã\n",
    "    # ()    : ã“ã®ã‚«ãƒƒã‚³å†…ã®éƒ¨åˆ†ã‚’æŠ½å‡ºã™ã‚‹\n",
    "    top_match = re.search(r\"top:\\s*(-?[\\d\\.]+)%\", style_str)\n",
    "    left_match = re.search(r\"left:\\s*(-?[\\d\\.]+)%\", style_str)\n",
    "    # æŠ½å‡ºã—ãŸæ–‡å­—åˆ—ã‚’floatã«å¤‰æ›\n",
    "    top_val = float(top_match.group(1)) if top_match else None\n",
    "    left_val = float(left_match.group(1)) if left_match else None\n",
    "    # æˆ»ã‚Šå€¤\n",
    "    return top_val, left_val\n",
    "\n",
    "def get_position_pred(driver):\n",
    "    # HorseIconã‚¯ãƒ©ã‚¹ã‚’æŒã¤ã™ã¹ã¦ã®è¦ç´ ã‚’å–å¾—ï¼ˆãƒªã‚¹ãƒˆå½¢å¼ã§è¿”ã£ã¦ãã‚‹ï¼‰\n",
    "    position_pred_elements = driver.find_elements(By.CLASS_NAME, \"HorseIcon\")\n",
    "    # çµæœã‚’æ ¼ç´ã™ã‚‹è¾æ›¸\n",
    "    dic_position_pred = {}\n",
    "    for element in position_pred_elements:\n",
    "        horse_number = element.get_attribute(\"id\")\n",
    "        position_pred = element.get_attribute(\"style\")\n",
    "        top_val, left_val = extract_style_values(position_pred)\n",
    "        dic_val = {}\n",
    "        dic_val[\"top\"] = top_val\n",
    "        dic_val[\"left\"] = left_val\n",
    "        # idãŒç©ºã§ãªã„å ´åˆã®ã¿è¿½åŠ \n",
    "        if horse_number:\n",
    "            dic_position_pred[horse_number] = dic_val\n",
    "    # æˆ»ã‚Šå€¤\n",
    "    return dic_position_pred\n",
    "\n",
    "@log_step\n",
    "def login_netkeiba(driver):\n",
    "    try:\n",
    "        driver.get(LOGIN_URL)\n",
    "    except:\n",
    "        print(\"ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ãŸãŒå‡¦ç†ã‚’ç¶™ç¶š\")\n",
    "        driver.execute_script(\"window.stop();\")\n",
    "    driver.find_element(By.NAME, \"login_id\").send_keys(LOGIN_ID)\n",
    "    pw_field = driver.find_element(By.NAME, \"pswd\")\n",
    "    pw_field.send_keys(LOGIN_PASSWORD)\n",
    "    pw_field.send_keys(Keys.ENTER)\n",
    "    time.sleep(3)\n",
    "\n",
    "@log_step\n",
    "def scrape_horse_shutuba_data(driver, num_horses):\n",
    "    \n",
    "    all_horses_data = []\n",
    "    # é¦¬ç•ªãƒ»é¦¬åå–å¾—\n",
    "    # é¦¬ç•ªãƒ»é¦¬åãƒ»é¦¬åãƒªãƒ³ã‚¯å–å¾—\n",
    "    for i in range(1, num_horses + 1):\n",
    "        try:\n",
    "            # é¦¬ç•ª\n",
    "            xpath_horse_number = df_config_netkeiba.loc[\"XPATH_HORSE_NUMBER_1_SHUTUBA\"].iloc[0] + str(i) + df_config_netkeiba.loc[\"XPATH_HORSE_NUMBER_2_SHUTUBA\"].iloc[0]\n",
    "            if is_xpath_present(driver, xpath_horse_number): # é€šå¸¸é€šã‚Šå‡ºèµ°\n",
    "                horse_number = driver.find_element(By.XPATH, xpath_horse_number).text.strip()\n",
    "            elif is_xpath_present(driver, f\"//*[@id='Netkeiba_Race_Nar_Shutuba']/div[1]/div[3]/div[3]/table/tbody/tr[{str(i)}]/td[2]\"): # å–æ¶ˆç­‰\n",
    "                horse_number = driver.find_element(By.XPATH, f\"//*[@id='Netkeiba_Race_Nar_Shutuba']/div[1]/div[3]/div[3]/table/tbody/tr[{str(i)}]/td[2]\").text.strip()\n",
    "                horse_data = Horse_Shutuba(\n",
    "                    horse_id = None,\n",
    "                    horse_name = None,\n",
    "                    jockey_id = None,\n",
    "                    jockey_name = None,\n",
    "                    popularity = None,\n",
    "                    odds = None,\n",
    "                    sex_and_age = None,\n",
    "                    weight = None,\n",
    "                    horse_number = horse_number,\n",
    "                    frame_number = None,\n",
    "                    position_1_top_pred = None,\n",
    "                    position_1_left_pred = None,\n",
    "                    position_2_top_pred = None,\n",
    "                    position_2_left_pred = None,\n",
    "                    position_3_top_pred = None,\n",
    "                    position_3_left_pred = None,\n",
    "                    position_4_top_pred = None,\n",
    "                    position_4_left_pred = None,\n",
    "                    position_1_top_pred_jockey_tendency = None,\n",
    "                    position_1_left_pred_jockey_tendency = None,\n",
    "                    position_2_top_pred_jockey_tendency = None,\n",
    "                    position_2_left_pred_jockey_tendency = None,\n",
    "                    position_3_top_pred_jockey_tendency = None,\n",
    "                    position_3_left_pred_jockey_tendency = None,\n",
    "                    position_4_top_pred_jockey_tendency = None,\n",
    "                    position_4_left_pred_jockey_tendency = None,\n",
    "                    style_pred = None,\n",
    "                    impost = None,\n",
    "                    last_3_furlongs_pred = None\n",
    "                )\n",
    "                all_horses_data.append(horse_data)\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "            # é¦¬åã¨é¦¬ID\n",
    "            xpath_horse_link_1 = df_config_netkeiba.loc[\"XPATH_HORSE_LINK_1_1_SHUTUBA\"].iloc[0] + str(i) + df_config_netkeiba.loc[\"XPATH_HORSE_LINK_1_2_SHUTUBA\"].iloc[0]\n",
    "            xpath_horse_link_2 = df_config_netkeiba.loc[\"XPATH_HORSE_LINK_2_1_SHUTUBA\"].iloc[0] + str(i) + df_config_netkeiba.loc[\"XPATH_HORSE_LINK_2_2_SHUTUBA\"].iloc[0]\n",
    "            if is_xpath_present(driver, xpath_horse_link_1):\n",
    "                xpath_horse_link = xpath_horse_link_1\n",
    "            elif is_xpath_present(driver, xpath_horse_link_2):\n",
    "                xpath_horse_link = xpath_horse_link_2\n",
    "            horse_link_elem = driver.find_element(By.XPATH, xpath_horse_link)\n",
    "            horse_name = horse_link_elem.text.strip()\n",
    "            horse_href = horse_link_elem.get_attribute(\"href\")\n",
    "            horse_id = horse_href.rstrip(\"/\").split(\"/\")[-1]\n",
    "            # é¨æ‰‹åã¨é¨æ‰‹ID\n",
    "            xpath_jockey_link = df_config_netkeiba.loc[\"XPATH_JOCKEY_LINK_1_SHUTUBA\"].iloc[0] + str(i) + df_config_netkeiba.loc[\"XPATH_JOCKEY_LINK_2_SHUTUBA\"].iloc[0]\n",
    "            jockey_link_elem = driver.find_element(By.XPATH, xpath_jockey_link)\n",
    "            jockey_name = jockey_link_elem.text.strip()\n",
    "            jockey_href = jockey_link_elem.get_attribute(\"href\")\n",
    "            jockey_id = jockey_href.rstrip(\"/\").split(\"/\")[-1]\n",
    "            # äººæ°—\n",
    "            xpath_popularity = df_config_netkeiba.loc[\"XPATH_POPULARITY_1_SHUTUBA\"].iloc[0] + str(i) + df_config_netkeiba.loc[\"XPATH_POPULARITY_2_SHUTUBA\"].iloc[0]\n",
    "            popularity = driver.find_element(By.XPATH, xpath_popularity).text\n",
    "            # ã‚ªãƒƒã‚º\n",
    "            xpath_odds = df_config_netkeiba.loc[\"XPATH_ODDS_1_SHUTUBA\"].iloc[0] + str(i) + df_config_netkeiba.loc[\"XPATH_ODDS_2_SHUTUBA\"].iloc[0]\n",
    "            odds = driver.find_element(By.XPATH, xpath_odds).text\n",
    "            # æ€§é½¢\n",
    "            xpath_sex_and_age = df_config_netkeiba.loc[\"XPATH_SEX_AND_AGE_1_SHUTUBA\"].iloc[0] + str(i) + df_config_netkeiba.loc[\"XPATH_SEX_AND_AGE_2_SHUTUBA\"].iloc[0]\n",
    "            sex_and_age = driver.find_element(By.XPATH, xpath_sex_and_age).text\n",
    "            # é¦¬ä½“é‡\n",
    "            xpath_weight = df_config_netkeiba.loc[\"XPATH_WEIGHT_1_SHUTUBA\"].iloc[0] + str(i) + df_config_netkeiba.loc[\"XPATH_WEIGHT_2_SHUTUBA\"].iloc[0]\n",
    "            weight = driver.find_element(By.XPATH, xpath_weight).text\n",
    "            # æ ç•ª\n",
    "            xpath_frame_number = df_config_netkeiba.loc[\"XPATH_FRAME_1_SHUTUBA\"].iloc[0] + str(i) + df_config_netkeiba.loc[\"XPATH_FRAME_2_SHUTUBA\"].iloc[0]\n",
    "            frame_number = driver.find_element(By.XPATH, xpath_frame_number).text\n",
    "            # æ–¤é‡\n",
    "            xpath_impost = df_config_netkeiba.loc[\"XPATH_IMPOSE_1_SHUTUBA\"].iloc[0] + str(i) + df_config_netkeiba.loc[\"XPATH_IMPOSE_2_SHUTUBA\"].iloc[0]\n",
    "            impost = driver.find_element(By.XPATH, xpath_impost).text\n",
    "            # å¾ŒåŠ3F\n",
    "            xpath_last_3_furlongs_pred = df_config_netkeiba.loc[\"XPATH_LAST_3_FURLONGS_PRED_1_SHUTUBA\"].iloc[0] + str(i) + df_config_netkeiba.loc[\"XPATH_LAST_3_FURLONGS_PRED_2_SHUTUBA\"].iloc[0]\n",
    "            if is_xpath_present(driver, xpath_last_3_furlongs_pred):\n",
    "                last_3_furlongs_pred = driver.find_element(By.XPATH, xpath_last_3_furlongs_pred).text\n",
    "            else:\n",
    "                last_3_furlongs_pred = None\n",
    "            # é¦¬ãƒ‡ãƒ¼ã‚¿ä½œæˆ\n",
    "            horse_data = Horse_Shutuba(\n",
    "                horse_id = horse_id,\n",
    "                horse_name = horse_name,\n",
    "                jockey_id = jockey_id,\n",
    "                jockey_name = jockey_name,\n",
    "                popularity = popularity,\n",
    "                odds = odds,\n",
    "                sex_and_age = sex_and_age,\n",
    "                weight = weight,\n",
    "                horse_number = horse_number,\n",
    "                frame_number = frame_number,\n",
    "                position_1_top_pred = None,\n",
    "                position_1_left_pred = None,\n",
    "                position_2_top_pred = None,\n",
    "                position_2_left_pred = None,\n",
    "                position_3_top_pred = None,\n",
    "                position_3_left_pred = None,\n",
    "                position_4_top_pred = None,\n",
    "                position_4_left_pred = None,\n",
    "                position_1_top_pred_jockey_tendency = None,\n",
    "                position_1_left_pred_jockey_tendency = None,\n",
    "                position_2_top_pred_jockey_tendency = None,\n",
    "                position_2_left_pred_jockey_tendency = None,\n",
    "                position_3_top_pred_jockey_tendency = None,\n",
    "                position_3_left_pred_jockey_tendency = None,\n",
    "                position_4_top_pred_jockey_tendency = None,\n",
    "                position_4_left_pred_jockey_tendency = None,\n",
    "                style_pred = None,\n",
    "                impost = impost,\n",
    "                last_3_furlongs_pred = last_3_furlongs_pred\n",
    "            )\n",
    "            \n",
    "            all_horses_data.append(horse_data)\n",
    "        except Exception as e:\n",
    "            print(f\"  é¦¬ç•ª{i}: ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•— ({e})\")\n",
    "    # æˆ»ã‚Šå€¤\n",
    "    return all_horses_data\n",
    "\n",
    "@log_step\n",
    "def scrape_horse_result_data(driver, num_horses):\n",
    "    \n",
    "    all_horses_data = []\n",
    "    # é¦¬ç•ªãƒ»é¦¬åå–å¾—\n",
    "    # é¦¬ç•ªãƒ»é¦¬åãƒ»é¦¬åãƒªãƒ³ã‚¯å–å¾—\n",
    "    for i in range(1, num_horses + 1):\n",
    "        try:\n",
    "            # ç€ç•ª\n",
    "            xpath_finish_rank = df_config_netkeiba.loc[\"XPATH_FINISH_RANK_1_RESULT\"].iloc[0] + str(i) + df_config_netkeiba.loc[\"XPATH_FINISH_RANK_2_RESULT\"].iloc[0]\n",
    "            finish_rank = driver.find_element(By.XPATH, xpath_finish_rank).text\n",
    "            # æ ç•ª\n",
    "            xpath_frame_number = df_config_netkeiba.loc[\"XPATH_FRAME_NUMBER_1_RESULT\"].iloc[0] + str(i) + df_config_netkeiba.loc[\"XPATH_FRAME_NUMBER_2_RESULT\"].iloc[0]\n",
    "            frame_number = driver.find_element(By.XPATH, xpath_frame_number).text\n",
    "            # é¦¬ç•ª\n",
    "            xpath_horse_number = df_config_netkeiba.loc[\"XPATH_HORSE_NUMBER_1_RESULT\"].iloc[0] + str(i) + df_config_netkeiba.loc[\"XPATH_HORSE_NUMBER_2_RESULT\"].iloc[0]\n",
    "            if is_xpath_present(driver, xpath_horse_number):\n",
    "                horse_number = driver.find_element(By.XPATH, xpath_horse_number).text.strip()\n",
    "            else:\n",
    "                continue\n",
    "            # é¦¬åã¨é¦¬ID\n",
    "            xpath_horse_link = df_config_netkeiba.loc[\"XPATH_HORSE_LINK_1_RESULT\"].iloc[0] + str(i) + df_config_netkeiba.loc[\"XPATH_HORSE_LINK_2_RESULT\"].iloc[0]\n",
    "            horse_link_elem = driver.find_element(By.XPATH, xpath_horse_link)\n",
    "            horse_name = horse_link_elem.text.strip()\n",
    "            horse_href = horse_link_elem.get_attribute(\"href\")\n",
    "            horse_id = horse_href.rstrip(\"/\").split(\"/\")[-1]\n",
    "            # æ€§é½¢\n",
    "            xpath_sex_and_age = df_config_netkeiba.loc[\"XPATH_SEX_AND_AGE_1_RESULT\"].iloc[0] + str(i) + df_config_netkeiba.loc[\"XPATH_SEX_AND_AGE_2_RESULT\"].iloc[0]\n",
    "            sex_and_age = driver.find_element(By.XPATH, xpath_sex_and_age).text\n",
    "            # æ–¤é‡\n",
    "            xpath_impost = df_config_netkeiba.loc[\"XPATH_IMPOSE_1_RESULT\"].iloc[0] + str(i) + df_config_netkeiba.loc[\"XPATH_IMPOSE_2_RESULT\"].iloc[0]\n",
    "            impost = driver.find_element(By.XPATH, xpath_impost).text\n",
    "            # é¨æ‰‹åã¨é¨æ‰‹ID\n",
    "            xpath_jockey_link = df_config_netkeiba.loc[\"XPATH_JOCKEY_LINK_1_RESULT\"].iloc[0] + str(i) + df_config_netkeiba.loc[\"XPATH_JOCKEY_LINK_2_RESULT\"].iloc[0]\n",
    "            jockey_link_elem = driver.find_element(By.XPATH, xpath_jockey_link)\n",
    "            jockey_name = jockey_link_elem.text.strip()\n",
    "            jockey_href = jockey_link_elem.get_attribute(\"href\")\n",
    "            jockey_id = jockey_href.rstrip(\"/\").split(\"/\")[-1]\n",
    "            # ã‚¿ã‚¤ãƒ \n",
    "            xpath_time = df_config_netkeiba.loc[\"XPATH_TIME_1_RESULT\"].iloc[0] + str(i) + df_config_netkeiba.loc[\"XPATH_TIME_2_RESULT\"].iloc[0]\n",
    "            time = driver.find_element(By.XPATH, xpath_time).text\n",
    "            # ç€å·®\n",
    "            xpath_diff = df_config_netkeiba.loc[\"XPATH_DIFF_1_RESULT\"].iloc[0] + str(i) + df_config_netkeiba.loc[\"XPATH_DIFF_2_RESULT\"].iloc[0]\n",
    "            diff = driver.find_element(By.XPATH, xpath_diff).text\n",
    "            # äººæ°—\n",
    "            xpath_popularity = df_config_netkeiba.loc[\"XPATH_POPULARITY_1_RESULT\"].iloc[0] + str(i) + df_config_netkeiba.loc[\"XPATH_POPULARITY_2_RESULT\"].iloc[0]\n",
    "            popularity = driver.find_element(By.XPATH, xpath_popularity).text\n",
    "            # ã‚ªãƒƒã‚º\n",
    "            xpath_odds = df_config_netkeiba.loc[\"XPATH_ODDS_1_RESULT\"].iloc[0] + str(i) + df_config_netkeiba.loc[\"XPATH_ODDS_2_RESULT\"].iloc[0]\n",
    "            odds = driver.find_element(By.XPATH, xpath_odds).text\n",
    "            # å¾ŒåŠ3F\n",
    "            xpath_last_3_furlongs = df_config_netkeiba.loc[\"XPATH_LAST_3_FURLONGS_1_RESULT\"].iloc[0] + str(i) + df_config_netkeiba.loc[\"XPATH_LAST_3_FURLONGS_2_RESULT\"].iloc[0]\n",
    "            last_3_furlongs = driver.find_element(By.XPATH, xpath_last_3_furlongs).text\n",
    "            # é¦¬ä½“é‡\n",
    "            xpath_weight = df_config_netkeiba.loc[\"XPATH_WEIGHT_1_RESULT\"].iloc[0] + str(i) + df_config_netkeiba.loc[\"XPATH_WEIGHT_2_RESULT\"].iloc[0]\n",
    "            weight = driver.find_element(By.XPATH, xpath_weight).text\n",
    "            # é¦¬ãƒ‡ãƒ¼ã‚¿ä½œæˆ\n",
    "            horse_data = Horse_Result(\n",
    "                finish_rank = finish_rank,\n",
    "                frame_number = frame_number,\n",
    "                horse_number = horse_number,\n",
    "                horse_id = horse_id,\n",
    "                horse_name = horse_name,\n",
    "                sex_and_age = sex_and_age,\n",
    "                impost =   impost,\n",
    "                jockey_id = jockey_id,\n",
    "                jockey_name = jockey_name,\n",
    "                time = time,\n",
    "                diff = diff,\n",
    "                popularity = popularity,\n",
    "                odds = odds,\n",
    "                last_3_furlongs = last_3_furlongs,\n",
    "                weight = weight\n",
    "            )\n",
    "            all_horses_data.append(horse_data)\n",
    "        except Exception as e:\n",
    "            print(f\"  é¦¬ç•ª{i}: ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•— ({e})\")\n",
    "    # æˆ»ã‚Šå€¤\n",
    "    return all_horses_data\n",
    "\n",
    "@log_step\n",
    "def scrape_race_data(driver, race_id, date):\n",
    "\n",
    "    try:\n",
    "        # ç«¶é¦¬å ´\n",
    "        racecourse = driver.find_element(By.CSS_SELECTOR, SELECTOR_RACECOURSE).text\n",
    "        # R\n",
    "        race_number = driver.find_element(By.CSS_SELECTOR, SELECTOR_RACE_NUMBER).text.replace(\"R\", \"\")\n",
    "        # é ­æ•°\n",
    "        num_horses = driver.find_element(By.CSS_SELECTOR, SELECTOR_NUM_HORSES).text\n",
    "        num_horses = int(num_horses.replace(\"é ­\", \"\").strip())\n",
    "        # ãƒ¬ãƒ¼ã‚¹æƒ…å ±ï¼ˆç™ºèµ°æ™‚åˆ»ã€ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã€è·é›¢ã€å‘ãï¼‰\n",
    "        race_info = driver.find_element(By.XPATH, XPATH_RACE_INFO).text\n",
    "        race_info = race_info.strip()\n",
    "        # \"/\"ã§åˆ†å‰²\n",
    "        parts = [p.strip() for p in race_info.split(\"/\")]            \n",
    "        # ç™ºèµ°æ™‚åˆ»ã‚’æŠ½å‡º\n",
    "        race_time = parts[0].replace(\"ç™ºèµ°\", \"\").strip()\n",
    "        ground_info = parts[1]\n",
    "        # ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚’æŠ½å‡º\n",
    "        ground_match = re.search(r\"(èŠ|ãƒ€)\", ground_info)\n",
    "        ground = ground_match.group(1) if ground_match else \"ä¸æ˜\"\n",
    "        # è·é›¢ã‚’æŠ½å‡º\n",
    "        distance_match = re.search(r\"(\\d+)m\", ground_info)\n",
    "        distance = int(distance_match.group(1)) if distance_match else -1\n",
    "        # å‘ãã‚’æŠ½å‡º\n",
    "        direction_match = re.search(r\"\\((å·¦|å³)\\)\", ground_info)\n",
    "        direction = direction_match.group(1) if direction_match else \"ä¸æ˜\"\n",
    "        # é¦¬ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º\n",
    "        if MODE == \"shutuba\":\n",
    "            horse_list = scrape_horse_shutuba_data(driver, num_horses)\n",
    "        elif MODE == \"result\":\n",
    "            horse_list = scrape_horse_result_data(driver, num_horses)\n",
    "        # ç«¶é¦¬å ´ãŒå¸¯åºƒã§ãªã„å ´åˆã¯äºˆæƒ³ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹\n",
    "        reliability = None\n",
    "        opinion = None\n",
    "        position_1 = None\n",
    "        position_2 = None\n",
    "        position_3 = None\n",
    "        position_4 = None\n",
    "        if MODE == \"shutuba\" and racecourse != \"å¸¯åºƒ(ã°)\":\n",
    "            if is_xpath_present(driver, df_config_netkeiba.loc[\"XPATH_CORNER_1\"].iloc[0]):\n",
    "                # 1äººæ°—ä¿¡é ¼åº¦\n",
    "                if is_xpath_present(driver, df_config_netkeiba.loc[\"XPATH_RELIABILITY\"].iloc[0]):\n",
    "                    reliability = driver.find_element(By.XPATH, df_config_netkeiba.loc[\"XPATH_RELIABILITY\"].iloc[0]).text\n",
    "                # è¦‹è§£\n",
    "                if is_xpath_present(driver, df_config_netkeiba.loc[\"XPATH_OPINION\"].iloc[0]):\n",
    "                    opinion = driver.find_element(By.XPATH, df_config_netkeiba.loc[\"XPATH_OPINION\"].iloc[0]).text\n",
    "                # ãƒã‚¸ã‚·ãƒ§ãƒ³äºˆæƒ³ï¼ˆ1ï¼‰\n",
    "                corner = driver.find_element(By.XPATH, df_config_netkeiba.loc[\"XPATH_CORNER_1\"].iloc[0]).text\n",
    "                dic_position_pred = get_position_pred(driver)\n",
    "                match corner:\n",
    "                    case \"ã‚¹ã‚¿ãƒ¼ãƒˆå¾Œ\":\n",
    "                        for horse in horse_list:\n",
    "                            horse.position_1_top_pred = dic_position_pred[f'Horse{horse.horse_number}'][\"top\"]\n",
    "                            horse.position_1_left_pred = dic_position_pred[f'Horse{horse.horse_number}'][\"left\"]\n",
    "                    case \"2ã‚³ãƒ¼ãƒŠãƒ¼\":\n",
    "                        for horse in horse_list:\n",
    "                            horse.position_2_top_pred = dic_position_pred[f'Horse{horse.horse_number}'][\"top\"]\n",
    "                            horse.position_2_left_pred = dic_position_pred[f'Horse{horse.horse_number}'][\"left\"]\n",
    "                    case \"3ã‚³ãƒ¼ãƒŠãƒ¼\":\n",
    "                        for horse in horse_list:\n",
    "                            horse.position_3_top_pred = dic_position_pred[f'Horse{horse.horse_number}'][\"top\"]\n",
    "                            horse.position_3_left_pred = dic_position_pred[f'Horse{horse.horse_number}'][\"left\"]\n",
    "                    case \"4ã‚³ãƒ¼ãƒŠãƒ¼\":\n",
    "                        for horse in horse_list:\n",
    "                            horse.position_4_top_pred = dic_position_pred[f'Horse{horse.horse_number}'][\"top\"]\n",
    "                            horse.position_4_left_pred = dic_position_pred[f'Horse{horse.horse_number}'][\"left\"]\n",
    "                # ãƒã‚¸ã‚·ãƒ§ãƒ³äºˆæƒ³ï¼ˆ2ï¼‰\n",
    "                driver.find_element(By.XPATH, df_config_netkeiba.loc[\"XPATH_CORNER_2\"].iloc[0]).click()\n",
    "                corner = driver.find_element(By.XPATH, df_config_netkeiba.loc[\"XPATH_CORNER_2\"].iloc[0]).text\n",
    "                dic_position_pred = get_position_pred(driver)\n",
    "                # ãƒã‚¸ã‚·ãƒ§ãƒ³äºˆæƒ³ã‚’é¦¬ã¨ç´ã¥ã‘ã‚‹\n",
    "                match corner:\n",
    "                    case \"ã‚¹ã‚¿ãƒ¼ãƒˆå¾Œ\":\n",
    "                        for horse in horse_list:\n",
    "                            horse.position_1_top_pred = dic_position_pred[f'Horse{horse.horse_number}'][\"top\"]\n",
    "                            horse.position_1_left_pred = dic_position_pred[f'Horse{horse.horse_number}'][\"left\"]\n",
    "                    case \"2ã‚³ãƒ¼ãƒŠãƒ¼\":\n",
    "                        for horse in horse_list:\n",
    "                            horse.position_2_top_pred = dic_position_pred[f'Horse{horse.horse_number}'][\"top\"]\n",
    "                            horse.position_2_left_pred = dic_position_pred[f'Horse{horse.horse_number}'][\"left\"]\n",
    "                    case \"3ã‚³ãƒ¼ãƒŠãƒ¼\":\n",
    "                        for horse in horse_list:\n",
    "                            horse.position_3_top_pred = dic_position_pred[f'Horse{horse.horse_number}'][\"top\"]\n",
    "                            horse.position_3_left_pred = dic_position_pred[f'Horse{horse.horse_number}'][\"left\"]\n",
    "                    case \"4ã‚³ãƒ¼ãƒŠãƒ¼\":\n",
    "                        for horse in horse_list:\n",
    "                            horse.position_4_top_pred = dic_position_pred[f'Horse{horse.horse_number}'][\"top\"]\n",
    "                            horse.position_4_left_pred = dic_position_pred[f'Horse{horse.horse_number}'][\"left\"]\n",
    "                # ãƒã‚¸ã‚·ãƒ§ãƒ³äºˆæƒ³ï¼ˆ3ï¼‰\n",
    "                driver.find_element(By.XPATH, df_config_netkeiba.loc[\"XPATH_CORNER_3\"].iloc[0]).click()\n",
    "                corner = driver.find_element(By.XPATH, df_config_netkeiba.loc[\"XPATH_CORNER_3\"].iloc[0]).text\n",
    "                dic_position_pred = get_position_pred(driver)\n",
    "                # ãƒã‚¸ã‚·ãƒ§ãƒ³äºˆæƒ³ã‚’é¦¬ã¨ç´ã¥ã‘ã‚‹\n",
    "                match corner:\n",
    "                    case \"ã‚¹ã‚¿ãƒ¼ãƒˆå¾Œ\":\n",
    "                        for horse in horse_list:\n",
    "                            horse.position_1_top_pred = dic_position_pred[f'Horse{horse.horse_number}'][\"top\"]\n",
    "                            horse.position_1_left_pred = dic_position_pred[f'Horse{horse.horse_number}'][\"left\"]\n",
    "                    case \"2ã‚³ãƒ¼ãƒŠãƒ¼\":\n",
    "                        for horse in horse_list:\n",
    "                            horse.position_2_top_pred = dic_position_pred[f'Horse{horse.horse_number}'][\"top\"]\n",
    "                            horse.position_2_left_pred = dic_position_pred[f'Horse{horse.horse_number}'][\"left\"]\n",
    "                    case \"3ã‚³ãƒ¼ãƒŠãƒ¼\":\n",
    "                        for horse in horse_list:\n",
    "                            horse.position_3_top_pred = dic_position_pred[f'Horse{horse.horse_number}'][\"top\"]\n",
    "                            horse.position_3_left_pred = dic_position_pred[f'Horse{horse.horse_number}'][\"left\"]\n",
    "                    case \"4ã‚³ãƒ¼ãƒŠãƒ¼\":\n",
    "                        for horse in horse_list:\n",
    "                            horse.position_4_top_pred = dic_position_pred[f'Horse{horse.horse_number}'][\"top\"]\n",
    "                            horse.position_4_left_pred = dic_position_pred[f'Horse{horse.horse_number}'][\"left\"]\n",
    "                # ã€Œé¨æ‰‹å‚¾å‘ã‚’è€ƒæ…®ã€ã‚’ãƒã‚§ãƒƒã‚¯\n",
    "                driver.find_element(By.XPATH, \"//*[@id='dev_check_01_03']\").click()\n",
    "                # ãƒã‚¸ã‚·ãƒ§ãƒ³äºˆæƒ³ï¼ˆ1ï¼‰\n",
    "                driver.find_element(By.XPATH, df_config_netkeiba.loc[\"XPATH_CORNER_1\"].iloc[0]).click()\n",
    "                corner = driver.find_element(By.XPATH, df_config_netkeiba.loc[\"XPATH_CORNER_1\"].iloc[0]).text\n",
    "                dic_position_pred = get_position_pred(driver)\n",
    "                match corner:\n",
    "                    case \"ã‚¹ã‚¿ãƒ¼ãƒˆå¾Œ\":\n",
    "                        for horse in horse_list:\n",
    "                            horse.position_1_top_pred_jockey_tendency = dic_position_pred[f'Horse{horse.horse_number}'][\"top\"]\n",
    "                            horse.position_1_left_pred_jockey_tendency = dic_position_pred[f'Horse{horse.horse_number}'][\"left\"]\n",
    "                    case \"2ã‚³ãƒ¼ãƒŠãƒ¼\":\n",
    "                        for horse in horse_list:\n",
    "                            horse.position_2_top_pred_jockey_tendency = dic_position_pred[f'Horse{horse.horse_number}'][\"top\"]\n",
    "                            horse.position_2_left_pred_jockey_tendency = dic_position_pred[f'Horse{horse.horse_number}'][\"left\"]\n",
    "                    case \"3ã‚³ãƒ¼ãƒŠãƒ¼\":\n",
    "                        for horse in horse_list:\n",
    "                            horse.position_3_top_pred_jockey_tendency = dic_position_pred[f'Horse{horse.horse_number}'][\"top\"]\n",
    "                            horse.position_3_left_pred_jockey_tendency = dic_position_pred[f'Horse{horse.horse_number}'][\"left\"]\n",
    "                    case \"4ã‚³ãƒ¼ãƒŠãƒ¼\":\n",
    "                        for horse in horse_list:\n",
    "                            horse.position_4_top_pred_jockey_tendency = dic_position_pred[f'Horse{horse.horse_number}'][\"top\"]\n",
    "                            horse.position_4_left_pred_jockey_tendency = dic_position_pred[f'Horse{horse.horse_number}'][\"left\"]\n",
    "                # ãƒã‚¸ã‚·ãƒ§ãƒ³äºˆæƒ³ï¼ˆ2ï¼‰\n",
    "                driver.find_element(By.XPATH, df_config_netkeiba.loc[\"XPATH_CORNER_2\"].iloc[0]).click()\n",
    "                corner = driver.find_element(By.XPATH, df_config_netkeiba.loc[\"XPATH_CORNER_2\"].iloc[0]).text\n",
    "                dic_position_pred = get_position_pred(driver)\n",
    "                # ãƒã‚¸ã‚·ãƒ§ãƒ³äºˆæƒ³ã‚’é¦¬ã¨ç´ã¥ã‘ã‚‹\n",
    "                match corner:\n",
    "                    case \"ã‚¹ã‚¿ãƒ¼ãƒˆå¾Œ\":\n",
    "                        for horse in horse_list:\n",
    "                            horse.position_1_top_pred_jockey_tendency = dic_position_pred[f'Horse{horse.horse_number}'][\"top\"]\n",
    "                            horse.position_1_left_pred_jockey_tendency = dic_position_pred[f'Horse{horse.horse_number}'][\"left\"]\n",
    "                    case \"2ã‚³ãƒ¼ãƒŠãƒ¼\":\n",
    "                        for horse in horse_list:\n",
    "                            horse.position_2_top_pred_jockey_tendency = dic_position_pred[f'Horse{horse.horse_number}'][\"top\"]\n",
    "                            horse.position_2_left_pred_jockey_tendency = dic_position_pred[f'Horse{horse.horse_number}'][\"left\"]\n",
    "                    case \"3ã‚³ãƒ¼ãƒŠãƒ¼\":\n",
    "                        for horse in horse_list:\n",
    "                            horse.position_3_top_pred_jockey_tendency = dic_position_pred[f'Horse{horse.horse_number}'][\"top\"]\n",
    "                            horse.position_3_left_pred_jockey_tendency = dic_position_pred[f'Horse{horse.horse_number}'][\"left\"]\n",
    "                    case \"4ã‚³ãƒ¼ãƒŠãƒ¼\":\n",
    "                        for horse in horse_list:\n",
    "                            horse.position_4_top_pred_jockey_tendency = dic_position_pred[f'Horse{horse.horse_number}'][\"top\"]\n",
    "                            horse.position_4_left_pred_jockey_tendency = dic_position_pred[f'Horse{horse.horse_number}'][\"left\"]\n",
    "                # ãƒã‚¸ã‚·ãƒ§ãƒ³äºˆæƒ³ï¼ˆ3ï¼‰\n",
    "                driver.find_element(By.XPATH, df_config_netkeiba.loc[\"XPATH_CORNER_3\"].iloc[0]).click()\n",
    "                corner = driver.find_element(By.XPATH, df_config_netkeiba.loc[\"XPATH_CORNER_3\"].iloc[0]).text\n",
    "                dic_position_pred = get_position_pred(driver)\n",
    "                # ãƒã‚¸ã‚·ãƒ§ãƒ³äºˆæƒ³ã‚’é¦¬ã¨ç´ã¥ã‘ã‚‹\n",
    "                match corner:\n",
    "                    case \"ã‚¹ã‚¿ãƒ¼ãƒˆå¾Œ\":\n",
    "                        for horse in horse_list:\n",
    "                            horse.position_1_top_pred_jockey_tendency = dic_position_pred[f'Horse{horse.horse_number}'][\"top\"]\n",
    "                            horse.position_1_left_pred_jockey_tendency = dic_position_pred[f'Horse{horse.horse_number}'][\"left\"]\n",
    "                    case \"2ã‚³ãƒ¼ãƒŠãƒ¼\":\n",
    "                        for horse in horse_list:\n",
    "                            horse.position_2_top_pred_jockey_tendency = dic_position_pred[f'Horse{horse.horse_number}'][\"top\"]\n",
    "                            horse.position_2_left_pred_jockey_tendency = dic_position_pred[f'Horse{horse.horse_number}'][\"left\"]\n",
    "                    case \"3ã‚³ãƒ¼ãƒŠãƒ¼\":\n",
    "                        for horse in horse_list:\n",
    "                            horse.position_3_top_pred_jockey_tendency = dic_position_pred[f'Horse{horse.horse_number}'][\"top\"]\n",
    "                            horse.position_3_left_pred_jockey_tendency = dic_position_pred[f'Horse{horse.horse_number}'][\"left\"]\n",
    "                    case \"4ã‚³ãƒ¼ãƒŠãƒ¼\":\n",
    "                        for horse in horse_list:\n",
    "                            horse.position_4_top_pred_jockey_tendency = dic_position_pred[f'Horse{horse.horse_number}'][\"top\"]\n",
    "                            horse.position_4_left_pred_jockey_tendency = dic_position_pred[f'Horse{horse.horse_number}'][\"left\"]                \n",
    "            # ã€Œæ—§ç‰ˆã®å±•é–‹äºˆæƒ³ã«åˆ‡ã‚Šæ›¿ãˆã‚‹ã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦è„šè³ªäºˆæƒ³ã‚’å–å¾—\n",
    "            driver.find_element(By.XPATH, \"//*[@id='Netkeiba_Race_Nar_Shutuba']/div[1]/div[3]/div[14]/div/div/label/span\").click()\n",
    "            list_lead = []\n",
    "            list_stalker = []\n",
    "            list_chaser = []\n",
    "            list_closer = []\n",
    "            # é€ƒã’\n",
    "            for i in range(1, num_horses + 1):\n",
    "                if is_xpath_present(driver, \"//*[@id='Netkeiba_Race_Nar_Shutuba']/div[1]/div[3]/div[16]/table/tbody/tr[1]/td/div[\" + str(i) + \"]/span[1]\"):\n",
    "                    list_lead.append(driver.find_element(By.XPATH, \"//*[@id='Netkeiba_Race_Nar_Shutuba']/div[1]/div[3]/div[16]/table/tbody/tr[1]/td/div[\" + str(i) + \"]/span[1]\").text)\n",
    "                else:\n",
    "                     break\n",
    "            # å…ˆè¡Œ\n",
    "            for i in range(1, num_horses + 1):\n",
    "                if is_xpath_present(driver, \"//*[@id='Netkeiba_Race_Nar_Shutuba']/div[1]/div[3]/div[16]/table/tbody/tr[2]/td/div[\" + str(i) + \"]/span[1]\"):\n",
    "                    list_stalker.append(driver.find_element(By.XPATH, \"//*[@id='Netkeiba_Race_Nar_Shutuba']/div[1]/div[3]/div[16]/table/tbody/tr[2]/td/div[\" + str(i) + \"]/span[1]\").text)\n",
    "                else:\n",
    "                     break\n",
    "            # å·®ã—\n",
    "            for i in range(1, num_horses + 1):\n",
    "                if is_xpath_present(driver, \"//*[@id='Netkeiba_Race_Nar_Shutuba']/div[1]/div[3]/div[16]/table/tbody/tr[3]/td/div[\" + str(i) + \"]/span[1]\"):\n",
    "                    list_chaser.append(driver.find_element(By.XPATH, \"//*[@id='Netkeiba_Race_Nar_Shutuba']/div[1]/div[3]/div[16]/table/tbody/tr[3]/td/div[\" + str(i) + \"]/span[1]\").text)\n",
    "                else:\n",
    "                     break\n",
    "            # è¿½è¾¼\n",
    "            for i in range(1, num_horses + 1):\n",
    "                if is_xpath_present(driver, \"//*[@id='Netkeiba_Race_Nar_Shutuba']/div[1]/div[3]/div[16]/table/tbody/tr[4]/td/div[\" + str(i) + \"]/span[1]\"):\n",
    "                    list_closer.append(driver.find_element(By.XPATH, \"//*[@id='Netkeiba_Race_Nar_Shutuba']/div[1]/div[3]/div[16]/table/tbody/tr[4]/td/div[\" + str(i) + \"]/span[1]\").text)\n",
    "                else:\n",
    "                     break\n",
    "            # è„šè³ªäºˆæƒ³ã‚’é¦¬ã¨ç´ã¥ã‘ã‚‹\n",
    "            for horse in horse_list:\n",
    "                if horse.horse_number in list_lead:\n",
    "                    horse.style_pred = STYLE_MAP.get(1)\n",
    "                elif horse.horse_number in list_stalker:\n",
    "                    horse.style_pred = STYLE_MAP.get(2)\n",
    "                elif horse.horse_number in list_chaser:\n",
    "                    horse.style_pred = STYLE_MAP.get(3)\n",
    "                elif horse.horse_number in list_closer:\n",
    "                    horse.style_pred = STYLE_MAP.get(4)\n",
    "        elif MODE == \"result\" and racecourse != \"å¸¯åºƒ(ã°)\":\n",
    "            if is_xpath_present(driver, df_config_netkeiba.loc[\"XPATH_RANK_1_CORNER\"].iloc[0]):\n",
    "                position_1 = driver.find_element(By.XPATH, df_config_netkeiba.loc[\"XPATH_RANK_1_CORNER\"].iloc[0]).text\n",
    "            if is_xpath_present(driver, df_config_netkeiba.loc[\"XPATH_RANK_2_CORNER\"].iloc[0]):\n",
    "                position_2 = driver.find_element(By.XPATH, df_config_netkeiba.loc[\"XPATH_RANK_2_CORNER\"].iloc[0]).text\n",
    "            if is_xpath_present(driver, df_config_netkeiba.loc[\"XPATH_RANK_3_CORNER\"].iloc[0]):\n",
    "                position_3 = driver.find_element(By.XPATH, df_config_netkeiba.loc[\"XPATH_RANK_3_CORNER\"].iloc[0]).text\n",
    "            if is_xpath_present(driver, df_config_netkeiba.loc[\"XPATH_RANK_4_CORNER\"].iloc[0]):\n",
    "                position_4 = driver.find_element(By.XPATH, df_config_netkeiba.loc[\"XPATH_RANK_4_CORNER\"].iloc[0]).text\n",
    "        # ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã«æ ¼ç´\n",
    "        race_data = Race(\n",
    "            race_id = race_id,\n",
    "            # race_name\n",
    "            race_date = date,\n",
    "            race_time = race_time,\n",
    "            num_horses = num_horses,\n",
    "            race_number = race_number,\n",
    "            # weather_name\n",
    "            # track_condition_name,\n",
    "            racecourse = racecourse,\n",
    "            ground = ground,\n",
    "            distance = distance,\n",
    "            direction = direction,\n",
    "            reliability = reliability,\n",
    "            opinion = opinion,\n",
    "            position_1 = position_1,\n",
    "            position_2 = position_2,\n",
    "            position_3 = position_3,\n",
    "            position_4 = position_4,\n",
    "            horses = horse_list\n",
    "        )\n",
    "        # å‡ºåŠ›ç¢ºèª\n",
    "        print(f\"\\nğŸ“„ å¹´æœˆæ—¥: {race_data.race_date} | ç«¶é¦¬å ´: {race_data.racecourse} | R: {race_data.race_number}\")\n",
    "        for horse in race_data.horses:\n",
    "            print(f\"  é¦¬ç•ª: {horse.horse_number}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Race ID: {race_id} ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—: {e}\")\n",
    "        return None\n",
    "    # æˆ»ã‚Šå€¤\n",
    "    return race_data\n",
    "\n",
    "@log_step\n",
    "def scrape_one_day_data(driver, date):\n",
    "    \"\"\"\n",
    "    ç«¶é¦¬å ´ã¨Rã§ãƒ«ãƒ¼ãƒ—\n",
    "    \"\"\"\n",
    "    all_races_data = []\n",
    "    # ç«¶é¦¬å ´ã®ãƒ«ãƒ¼ãƒ—\n",
    "    for place_code in PLACE_MAP:\n",
    "        # Rã®ãƒ«ãƒ¼ãƒ—\n",
    "        for race_num in RACE_NUMBERS:\n",
    "            yyyy = date.strftime(\"%Y\")\n",
    "            mmdd = date.strftime(\"%m%d\")\n",
    "            race_id = f\"{yyyy}{place_code}{mmdd}{race_num}\"\n",
    "            race_url = f\"https://nar.netkeiba.com/race/{MODE}.html?race_id={race_id}\"\n",
    "            try:\n",
    "                driver.get(race_url)\n",
    "            except:\n",
    "                print(\"ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ãŸãŒå‡¦ç†ã‚’ç¶™ç¶š\")\n",
    "                driver.execute_script(\"window.stop();\")\n",
    "            time.sleep(1)\n",
    "            race_data = scrape_race_data(driver, race_id, date)\n",
    "            # 1Rã®race_dataãŒNoneã ã£ãŸã‚‰ãã®ç«¶é¦¬å ´ã§ã¯é–‹å‚¬ã—ã¦ã„ãªã„ãŸã‚Rã®ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ãŸã„\n",
    "            if race_data is None:\n",
    "                break\n",
    "            all_races_data.append(race_data)\n",
    "    # æˆ»ã‚Šå€¤\n",
    "    return all_races_data\n",
    "\n",
    "@log_step\n",
    "def main_scraper(driver, date_list):\n",
    "    \"\"\"\n",
    "    å¹´æœˆæ—¥ã§ãƒ«ãƒ¼ãƒ—\n",
    "    \"\"\"\n",
    "    all_days_data = []\n",
    "    # å¹´æœˆæ—¥ã®ãƒ«ãƒ¼ãƒ—\n",
    "    for date in date_list:\n",
    "        # å¹´æœˆæ—¥ã®URLã§ã‚¢ã‚¯ã‚»ã‚¹\n",
    "        date_str = date.strftime(\"%Y%m%d\")\n",
    "        race_list_url = RACE_LIST_URL + date_str\n",
    "        try:\n",
    "            driver.get(race_list_url)\n",
    "        except:\n",
    "            print(\"ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ãŸãŒå‡¦ç†ã‚’ç¶™ç¶š\")\n",
    "            driver.execute_script(\"window.stop();\")\n",
    "        one_day_data = scrape_one_day_data(driver, date)\n",
    "        all_days_data.append(one_day_data)\n",
    "    # æˆ»ã‚Šå€¤\n",
    "    return all_days_data\n",
    "\n",
    "@log_step\n",
    "def save_to_csv(final_result, filename=\"race_data.csv\"):\n",
    "    \"\"\"\n",
    "    ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµæœï¼ˆRaceã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆï¼‰ã‚’å¹³å¦åŒ–ã—ã¦CSVã«å‡ºåŠ›ã™ã‚‹\n",
    "    \"\"\"\n",
    "    flattened_data = []\n",
    "\n",
    "    # final_result ã¯ [ [Race1, Race2, ...], [Race1, Race2, ...] ] ã¨ã„ã†2æ¬¡å…ƒãƒªã‚¹ãƒˆ\n",
    "    for day_data in final_result:\n",
    "        for race in day_data:\n",
    "            # ãƒ¬ãƒ¼ã‚¹æƒ…å ±ã®å…±é€šé …ç›®ã‚’è¾æ›¸åŒ– (horsesãƒªã‚¹ãƒˆä»¥å¤–ã‚’å–å¾—)\n",
    "            race_info = {\n",
    "                \"race_id\": race.race_id,\n",
    "                \"race_date\": race.race_date.strftime(\"%Y-%m-%d\") if isinstance(race.race_date, datetime) else race.race_date,\n",
    "                \"race_time\": race.race_time,\n",
    "                \"num_horses\": race.num_horses,\n",
    "                \"race_number\": race.race_number,\n",
    "                \"racecourse\": race.racecourse,\n",
    "                \"ground\": race.ground,\n",
    "                \"distance\": race.distance,\n",
    "                \"direction\": race.direction,\n",
    "                \"reliability\": race.reliability,\n",
    "                # \"opinion\": race.opinion,\n",
    "                \"position_1\": race.position_1,\n",
    "                \"position_2\": race.position_2,\n",
    "                \"position_3\": race.position_3,\n",
    "                \"position_4\": race.position_4,\n",
    "            }\n",
    "\n",
    "            # ãã®ãƒ¬ãƒ¼ã‚¹ã«å±ã™ã‚‹é¦¬ã®ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ\n",
    "            for horse in race.horses:\n",
    "                # é¦¬ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¾æ›¸åŒ–\n",
    "                horse_info = vars(horse)\n",
    "                \n",
    "                # ãƒ¬ãƒ¼ã‚¹æƒ…å ±ã¨é¦¬æƒ…å ±ã‚’çµ±åˆã—ãŸæ–°ã—ã„è¾æ›¸ã‚’ä½œæˆ\n",
    "                combined_dict = {**race_info, **horse_info}\n",
    "                flattened_data.append(combined_dict)\n",
    "\n",
    "    if not flattened_data:\n",
    "        print(\"å‡ºåŠ›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "        return\n",
    "\n",
    "    # DataFrameã«å¤‰æ›\n",
    "    df = pd.DataFrame(flattened_data)\n",
    "\n",
    "    # CSVå‡ºåŠ› (æ—¥æœ¬èªæ–‡å­—åŒ–ã‘é˜²æ­¢ã®ãŸã‚ utf-8-sig ã‚’æŒ‡å®š)\n",
    "    df.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "    print(f\"âœ… CSVå‡ºåŠ›ãŒå®Œäº†ã—ã¾ã—ãŸ: {filename}\")\n",
    "\n",
    "# def get_target_shutuba_date():\n",
    "#     \"\"\"shutubaãƒ‡ãƒ¼ã‚¿å–å¾—å¯¾è±¡ã®å¹´æœˆæ—¥ã‚’èª­ã¿è¾¼ã‚€\"\"\" \n",
    "#     with open('C:\\\\keiba\\\\tool\\\\config.json', 'r', encoding='utf-8') as f:\n",
    "#         data = json.load(f)\n",
    "\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def move_target_files(source_dir_path, target_dir_path, search_pattern):\n",
    "    # 1. ãƒ‘ã‚¹ã‚’ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦å®šç¾©\n",
    "    source_dir = Path(source_dir_path)\n",
    "    target_dir = Path(target_dir_path)\n",
    "\n",
    "    # 2. ç§»å‹•å…ˆã®ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ\n",
    "    # if not target_dir.exists():\n",
    "    #     target_dir.mkdir(parents=True)\n",
    "    #     print(f\"ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã¾ã—ãŸ: {target_dir}\")\n",
    "\n",
    "    # 3. æ¡ä»¶ã«åˆã†ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ã—ã¦ç§»å‹•\n",
    "    files = list(source_dir.glob(search_pattern))\n",
    "\n",
    "    if not files:\n",
    "        print(\"ç§»å‹•å¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ\")\n",
    "        return\n",
    "\n",
    "    for file_path in files:\n",
    "        # ç§»å‹•å…ˆã®ãƒ•ãƒ«ãƒ‘ã‚¹ã‚’ä½œæˆ\n",
    "        destination = target_dir / file_path.name\n",
    "        \n",
    "        # ç§»å‹•å®Ÿè¡Œï¼ˆåŒåãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°ä¸Šæ›¸ãï¼‰\n",
    "        shutil.move(str(file_path), str(destination))\n",
    "        print(f\"ç§»å‹•å®Œäº†: {file_path.name} -> {target_dir.name}\")\n",
    "#         return data.get(\"target_shutuba_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acef519-d3df-4764-b440-430e222aa683",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ãƒ¡ã‚¤ãƒ³å‡¦ç† ###\n",
    "\n",
    "# å‰æ—¥ã®shutuba/resultãƒ•ã‚¡ã‚¤ãƒ«ã‚’oldãƒ•ã‚©ãƒ«ãƒ€ã«ç§»å‹•\n",
    "move_target_files(rf\"C:\\keiba\\tool\\{MODE}\", rf\"C:\\keiba\\tool\\{MODE}\\old\", f\"{MODE}*\")\n",
    "# ä»Šæ—¥ã®å¹´æœˆæ—¥\n",
    "today_str = datetime.now().strftime('%Y%m%d')\n",
    "# today_str = \"20260207\"\n",
    "# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æº–å‚™\n",
    "service = Service(PATH_CHROME_DRIVER)\n",
    "options = webdriver.ChromeOptions()\n",
    "# options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "# ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š\n",
    "driver.set_page_load_timeout(30)\n",
    "# ãƒ­ã‚°ã‚¤ãƒ³\n",
    "login_netkeiba(driver)\n",
    "# é–‹å§‹æ—¥ï½çµ‚äº†æ—¥\n",
    "# start_date = \"20260201\"\n",
    "# end_date = \"20260219\"\n",
    "date_list = pd.date_range(\n",
    "    start=today_str,\n",
    "    end=today_str,\n",
    "    freq='D'\n",
    ")\n",
    "# date_list = pd.date_range(\n",
    "#     start=start_date,\n",
    "#     end=end_date,\n",
    "#     freq='D'\n",
    "# )\n",
    "# ãƒ‡ãƒ¼ã‚¿å–å¾—\n",
    "final_result = main_scraper(driver, date_list)\n",
    "# CSVã¸ä¿å­˜\n",
    "save_to_csv(final_result, f\"C:\\\\keiba\\\\tool\\\\{MODE}\\\\{MODE}_{today_str}.csv\")\n",
    "# save_to_csv(final_result, f\"C:\\\\keiba\\\\tool\\\\{MODE}\\\\{MODE}_{start_date}_{end_date}.csv\", encoding='cp932')\n",
    "# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµ‚äº†\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d2c5c4-b3da-4106-be46-e16c9382dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åœ°æ–¹ç«¶é¦¬ https://nar.netkeiba.com/top/race_list.html?kaisai_date=YYYYMMDD\n",
    "# æ³¢ä¹±åº¦ https://nar.sp.netkeiba.com/race/compatibility.html\n",
    "# èª¿å­åå·®å€¤ https://race.sp.netkeiba.com/barometer/profile.html?kaisai_date=YYYYMMDD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
